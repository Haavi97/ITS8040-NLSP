{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Default_independent_project_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dXLUiLBL__R7",
        "OPm3-daEqWP2",
        "uab8IEZdoJM_",
        "bBs7fnCn_ZXY",
        "i3kc6ozYVoo1",
        "tBLqZ6BMXeN7",
        "1p0VaHZP9Beu",
        "POWaEnWjnRf_",
        "c7Dx82CJpZi9",
        "QdkY_C2txEoD",
        "SBpIYV8MFGT8",
        "R7DvuE4DGwt1"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haavi97/ITS8040-NLSP/blob/master/Default_independent_project_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDOAOeayqH1R"
      },
      "source": [
        "# Task description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTfOjDBLLvIJ"
      },
      "source": [
        "The \"default\" project topic is about Aspect-Based Sentiment Analysis (ABSA). By \"default\" it is meant that you are supposed to choose this topic if you don't have any preferences about the topic yourself. You are free to choose any other sufficiently challenging topic, but please consult with the lecturer.\n",
        "\n",
        "The task comes from the SemEval 2016 Shared Task 5: http://alt.qcri.org/semeval2016/task5/\n",
        "\n",
        "There are different subtasks and slots in this task. You can limit you work on Task 1 Slot 1: Aspect Category Detection, and you can further focus on the restaurant domain only.\n",
        "\n",
        "The task is: given a sentence taken from a restaurant review, your system has to decide about which aspect category of the restaurant this sentence is, if any. The number of different aspect categories is fixed. One sentnce can correspond to zero, one or more aspect categories.\n",
        "\n",
        "Some examples:\n",
        "\n",
        "*   \"I was very disappointed with this restaurant.\" -> RESTAURANT#GENERAL\n",
        "*   \"I’ve asked a cart attendant for a lotus leaf wrapped rice and she replied back rice and just walked away.\" -> SERVICE#GENERAL\n",
        "*   \"Chow fun was dry; pork shu mai was more than usually greasy and had to share a table with loud and rude family.\" -> FOOD#QUALITY, AMBIENCE#GENERAL\n",
        "\n",
        "The Slot 3 of the task would be finding the polarity (negative, neutral, positive) of the aspect, but you don't have to implement this.\n",
        "\n",
        "Since the data and evaluation tools for this Shared task come in quite complex form, I have implemented very basic data loading for you, together with a simplest possible sklearn-based implementation for this task.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwYQtYiEO4kd"
      },
      "source": [
        "I have packed the data for the restaurant domain for this subtask on my site. Let's download it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VruNWeGQ85Dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a7b973-bdee-4657-f7d9-7f181a316dde"
      },
      "source": [
        "! wget --no-check-certificate https://www.phon.ioc.ee/~tanela/tmp/absa-en-restaurant.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-05 16:29:50--  https://www.phon.ioc.ee/~tanela/tmp/absa-en-restaurant.zip\n",
            "Resolving www.phon.ioc.ee (www.phon.ioc.ee)... 193.40.251.126\n",
            "Connecting to www.phon.ioc.ee (www.phon.ioc.ee)|193.40.251.126|:443... connected.\n",
            "WARNING: cannot verify www.phon.ioc.ee's certificate, issued by ‘CN=TERENA SSL CA 3,O=TERENA,L=Amsterdam,ST=Noord-Holland,C=NL’:\n",
            "  Issued certificate has expired.\n",
            "WARNING: no certificate subject alternative name matches\n",
            "\trequested host name ‘www.phon.ioc.ee’.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 136921 (134K) [application/zip]\n",
            "Saving to: ‘absa-en-restaurant.zip.1’\n",
            "\n",
            "absa-en-restaurant. 100%[===================>] 133.71K   204KB/s    in 0.7s    \n",
            "\n",
            "2021-06-05 16:29:52 (204 KB/s) - ‘absa-en-restaurant.zip.1’ saved [136921/136921]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_zt54N989bW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ffbb606-2672-4d6f-c1f4-709fb3428140"
      },
      "source": [
        "! unzip absa-en-restaurant.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  absa-en-restaurant.zip\n",
            "replace ABSA16_Restaurants_Train_SB1_v2.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace EN_REST_SB1_TEST.xml.gold? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJiLrjJYPGf0"
      },
      "source": [
        "There are two files: training and test files. Both are in XML formats. Let's  take a peek:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqQznoWI9Gfe"
      },
      "source": [
        "#! head -20 ABSA16_Restaurants_Train_SB1_v2.xml  "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gekhfl_29N51"
      },
      "source": [
        "#! head -20 ABSA16_Restaurants_Train_SB1_v2.xml  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw5X3UIhZOOA"
      },
      "source": [
        "There is a lot of information in this XML: each sentence has a list of Opinions, where each Opinion consists of category, polarity and the target word or phrase. We are really interested only in the raw sentence and the corresponding opinion categories.\n",
        "\n",
        "There are many ways to parse XML in Python. In this example we use a method that parses XML to Python dict, which is we will then process via loops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9bSdaZk9RJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95598660-0ef8-4ec9-c7d2-87c8f2e54344"
      },
      "source": [
        "! pip install xmltodict"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (0.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNTRKIio-g3e"
      },
      "source": [
        "import xmltodict as xd\n",
        "\n",
        "\n",
        "with open('EN_REST_SB1_TEST.xml.gold','rb') as f:\n",
        "    d = xd.parse(f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0sxmb5s-ug0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bbd7b2b-6563-42bd-b403-1b5537b3b280"
      },
      "source": [
        "d[\"Reviews\"][\"Review\"][0][\"sentences\"][\"sentence\"][0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('@id', 'en_BlueRibbonSushi_478218171:0'),\n",
              "             ('text', 'Yum!'),\n",
              "             ('Opinions',\n",
              "              OrderedDict([('Opinion',\n",
              "                            OrderedDict([('@target', 'NULL'),\n",
              "                                         ('@category', 'FOOD#QUALITY'),\n",
              "                                         ('@polarity', 'positive'),\n",
              "                                         ('@from', '0'),\n",
              "                                         ('@to', '0')]))]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRHwXfhvaJMT"
      },
      "source": [
        "Here is the function that parses the XML and returns a list containing sentences and the corresponding list of categories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBjDpQc6-xpG"
      },
      "source": [
        "def read_data(filename):\n",
        "  result = []\n",
        "  with open(filename,'rb') as f:\n",
        "    d = xd.parse(f, force_list=('sentence', 'Opinion'))\n",
        "  for review in d[\"Reviews\"][\"Review\"]:\n",
        "    #print(review)\n",
        "    for sentence in review[\"sentences\"][\"sentence\"]:\n",
        "      \n",
        "      text = sentence[\"text\"]\n",
        "      opinion_cats = []\n",
        "      \n",
        "      if \"Opinions\" in sentence and sentence[\"Opinions\"] is not None:\n",
        "        opinions = sentence[\"Opinions\"][\"Opinion\"]\n",
        "        for opinion in opinions:\n",
        "          opinion_cats.append(opinion[\"@category\"])\n",
        "      result.append((text, opinion_cats))\n",
        "  return result\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGpT08S_AtAI"
      },
      "source": [
        "train_data = read_data(\"ABSA16_Restaurants_Train_SB1_v2.xml\")\n",
        "test_data = read_data(\"EN_REST_SB1_TEST.xml.gold\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--w93Sg4ePQn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11aae69-6df5-4a50-a007-f01607162f10"
      },
      "source": [
        "print(len(train_data), len(test_data))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000 676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20RpEpp9Azno"
      },
      "source": [
        "#train_data[:5]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXLUiLBL__R7"
      },
      "source": [
        "# Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPm3-daEqWP2"
      },
      "source": [
        "## Multilabel binarizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TvfCaAJanRj"
      },
      "source": [
        "So, each sentence can have zero or more categories. This task is called multi-label classification, as opposed to single-label classification where each sample corresponds to one and only one category.\n",
        "\n",
        "The sklearn package has some useful utilities for multi-label classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxSuYx03Dub3"
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNAU8zmkbhdI"
      },
      "source": [
        "MultiLabelBinarizer builds a mapping from multi-label labels to IDs, and also constructs a label matrix for our training ans test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAVKh_ALIVme"
      },
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "train_labels = mlb.fit_transform([set(sample[1]) for sample in train_data])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeHPL6aMJDmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a66443d-c8dd-49e8-bcfc-2926160d6778"
      },
      "source": [
        "train_labels[0:5]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wWDXL7BJPTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b227899-f202-4f79-f525-124dd24edf64"
      },
      "source": [
        "mlb.classes_"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['AMBIENCE#GENERAL', 'DRINKS#PRICES', 'DRINKS#QUALITY',\n",
              "       'DRINKS#STYLE_OPTIONS', 'FOOD#PRICES', 'FOOD#QUALITY',\n",
              "       'FOOD#STYLE_OPTIONS', 'LOCATION#GENERAL', 'RESTAURANT#GENERAL',\n",
              "       'RESTAURANT#MISCELLANEOUS', 'RESTAURANT#PRICES', 'SERVICE#GENERAL'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CWgZlI0T8sl"
      },
      "source": [
        "#print(test_data)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gHEvKiUJc6O"
      },
      "source": [
        "test_labels = mlb.transform([set(sample[1]) for sample in test_data])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnVk_1f2gQaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86472c9d-830f-4f48-c796-c2e6f9248e7a"
      },
      "source": [
        "test_labels[0:5]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J022vabVb0_I"
      },
      "source": [
        "So, our labels are now stored as binary matrices -- exactly as we need them.\n",
        "\n",
        "Let's also construct a list of training inputs, as sklearn likes it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQAKqSS-h7Wu"
      },
      "source": [
        "train_text = [review[0] for review in train_data]\n",
        "test_text = [review[0] for review in test_data]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pK7VcpdiHPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bdbcb4f-125e-4655-ca8c-4aedd0159419"
      },
      "source": [
        "train_text[0:5]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Judging from previous posts this used to be a good place, but not any longer.',\n",
              " 'We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.',\n",
              " 'They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.',\n",
              " 'The food was lousy - too sweet or too salty and the portions tiny.',\n",
              " 'After all that, they complained to me about the small tip.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uab8IEZdoJM_"
      },
      "source": [
        "## Data shape\n",
        "\n",
        "Printing data to have a clear picture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mog7s0wvoW7v",
        "outputId": "6467f463-0bf6-4412-e699-6220b77aa347"
      },
      "source": [
        "print('Train text data is of type: {}'.format(type(train_text)))\n",
        "print('Train label data is of type: {}'.format(type(train_labels)))\n",
        "print('Train text size: {}'.format(len(train_text)))\n",
        "print('Test text size: {}'.format(len(test_text)))\n",
        "print('Train labels size: {}'.format(train_labels.shape))\n",
        "print('Test labels size: {}'.format(test_labels.shape))\n",
        "n_labels = test_labels.shape[1]\n",
        "print('Number of labels: {}'.format(n_labels))\n",
        "TAGS = mlb.classes_\n",
        "print('\\nThis are the different labels:')\n",
        "print(TAGS)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train text data is of type: <class 'list'>\n",
            "Train label data is of type: <class 'numpy.ndarray'>\n",
            "Train text size: 2000\n",
            "Test text size: 676\n",
            "Train labels size: (2000, 12)\n",
            "Test labels size: (676, 12)\n",
            "Number of labels: 12\n",
            "\n",
            "This are the different labels:\n",
            "['AMBIENCE#GENERAL' 'DRINKS#PRICES' 'DRINKS#QUALITY'\n",
            " 'DRINKS#STYLE_OPTIONS' 'FOOD#PRICES' 'FOOD#QUALITY' 'FOOD#STYLE_OPTIONS'\n",
            " 'LOCATION#GENERAL' 'RESTAURANT#GENERAL' 'RESTAURANT#MISCELLANEOUS'\n",
            " 'RESTAURANT#PRICES' 'SERVICE#GENERAL']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBs7fnCn_ZXY"
      },
      "source": [
        "## OneVsRestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwRkaD4wcE6q"
      },
      "source": [
        "Now we can train a simple multi-label classifier.\n",
        "\n",
        "We use Sklearn's OneVsRestClassifier to do this. This basically builds a seperate base classifier for each of our labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6WxqVrBg4X4"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "text_clf = Pipeline([\n",
        "     ('vect', CountVectorizer()),\n",
        "     ('tfidf', TfidfTransformer()),\n",
        "     ('clf',  OneVsRestClassifier(LogisticRegression()))\n",
        " ])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuDR3_Z_hka8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42eb156b-ea42-4aa9-e4ea-28b5b762465a"
      },
      "source": [
        "text_clf.fit(train_text, train_labels )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=Non...\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 OneVsRestClassifier(estimator=LogisticRegression(C=1.0,\n",
              "                                                                  class_weight=None,\n",
              "                                                                  dual=False,\n",
              "                                                                  fit_intercept=True,\n",
              "                                                                  intercept_scaling=1,\n",
              "                                                                  l1_ratio=None,\n",
              "                                                                  max_iter=100,\n",
              "                                                                  multi_class='auto',\n",
              "                                                                  n_jobs=None,\n",
              "                                                                  penalty='l2',\n",
              "                                                                  random_state=None,\n",
              "                                                                  solver='lbfgs',\n",
              "                                                                  tol=0.0001,\n",
              "                                                                  verbose=0,\n",
              "                                                                  warm_start=False),\n",
              "                                     n_jobs=None))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKFXy8x7chr3"
      },
      "source": [
        "Classifier is trained. Let's first see how can we apply it on test data. What comes out when we feed it some test data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUBVNMOMiMdH"
      },
      "source": [
        "test_predictions = text_clf.predict(test_text)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BljUvwTpjBW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e63384-cb23-431f-f505-632083c422ff"
      },
      "source": [
        "test_predictions[0:5]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Bm_vDsET8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f129f4-b1bb-47c5-b354-262f78e7f610"
      },
      "source": [
        "test_labels[0:5]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt3PUdPbcs88"
      },
      "source": [
        "So, the output of our classifier is also a binary matrix. We can evaluate the performance of our model using F1 measure (which is a geometric mean of precision and recall). \n",
        "\n",
        "F1 measure can be computed for each label independently and then merged using either macro or micro averaging. We will use micro-averaging that sums up the individual true positives, false positives, and false negatives of the system for different sets and the apply them to get the statistics. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqxTrW3AiSSy"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ_fjQSgigIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8217512-c09a-474f-bbbc-fde00767f48c"
      },
      "source": [
        "f1_score(test_labels,\n",
        "         test_predictions,\n",
        "         average='micro')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4503441494591937"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2vnMB7eiuTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85bdcc06-a1df-405c-d5d8-7a9805be50cf"
      },
      "source": [
        "print(classification_report(test_labels, test_predictions, target_names=mlb.classes_, zero_division=0))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          precision    recall  f1-score   support\n",
            "\n",
            "        AMBIENCE#GENERAL       1.00      0.21      0.35        57\n",
            "           DRINKS#PRICES       0.00      0.00      0.00         3\n",
            "          DRINKS#QUALITY       0.00      0.00      0.00        21\n",
            "    DRINKS#STYLE_OPTIONS       0.00      0.00      0.00        12\n",
            "             FOOD#PRICES       0.00      0.00      0.00        22\n",
            "            FOOD#QUALITY       0.78      0.54      0.64       226\n",
            "      FOOD#STYLE_OPTIONS       0.00      0.00      0.00        48\n",
            "        LOCATION#GENERAL       0.00      0.00      0.00        13\n",
            "      RESTAURANT#GENERAL       0.84      0.23      0.36       142\n",
            "RESTAURANT#MISCELLANEOUS       0.00      0.00      0.00        33\n",
            "       RESTAURANT#PRICES       0.00      0.00      0.00        21\n",
            "         SERVICE#GENERAL       0.95      0.43      0.60       145\n",
            "\n",
            "               micro avg       0.84      0.31      0.45       743\n",
            "               macro avg       0.30      0.12      0.16       743\n",
            "            weighted avg       0.66      0.31      0.41       743\n",
            "             samples avg       0.32      0.28      0.29       743\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ILNRIidLtJe"
      },
      "source": [
        "It's now your task to improve this.\n",
        "\n",
        "You can try a lot of things to make the classifier more accurate. Of course, it's very recommended to try different DNN based approaches. \n",
        "\n",
        "Note that there are only 2000 training sentences. This makes the task basically an excercise of transfer learning. You can try using pre-trained word embeddings, pre-trained models like BERT, etc.\n",
        "\n",
        "Note that the labels have some structure in them. Each label consists of two parts: e.g. FOOD#QUALITY consists of FOOD and QUALITY. Maybe try splitting the labels into two parts and predicting each part independanty? Of course, you need to glue them back up when doing evaluation.\n",
        "\n",
        "Multi-label classification can be easily handled with neural network models with a model that has one output for each label, but instead of simple cross-entropy, binary cross-entropy has to be used for optimization.\n",
        "\n",
        "Multi-label classification is a quite popular task and you can find a lot of tutorials on the internet. For example, many many text classification where a text can be assigned many tags (as in StackOverflow) are multi-label tasks.\n",
        "\n",
        "\n",
        "Check the slides of Lecture 1 on how the final project should look like, what parts it should contain and how it will be graded.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3kc6ozYVoo1"
      },
      "source": [
        "## OneVsOne Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icGZVw0IS_Q_"
      },
      "source": [
        "def get_index(l):\n",
        "  try:\n",
        "    return list(l).index(1)\n",
        "  except: \n",
        "    #print(l)\n",
        "    return 13"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqL-prRmUu2R"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def reverse(l):\n",
        "  result = []\n",
        "  for e in l:\n",
        "    zeros = np.zeros(12, int)\n",
        "    if e != 13:\n",
        "      zeros[e] = 1\n",
        "    result.append(zeros)\n",
        "  return np.array(result)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuwKorIkjdA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1afe75fa-8800-46c8-a3bf-7c55a89aa169"
      },
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "text_clf_1vs1 = Pipeline([\n",
        "     ('vect', CountVectorizer()),\n",
        "     ('tfidf', TfidfTransformer()),\n",
        "     ('clf',  OneVsOneClassifier(LogisticRegression()))\n",
        " ])\n",
        "train_labels_1vs1 = list(map(lambda x: get_index(x), train_labels))\n",
        "text_clf_1vs1.fit(train_text, train_labels_1vs1)\n",
        "\n",
        "test_predictions = text_clf_1vs1.predict(test_text)\n",
        "\n",
        "test_predictions = reverse(test_predictions)\n",
        "print(test_predictions)\n",
        "test_labels_1vs1 = list(map(lambda x: get_index(x), test_labels))\n",
        "print(test_predictions)\n",
        "f1 = f1_score(test_labels,\n",
        "         test_predictions,\n",
        "         average='micro')\n",
        "print('F1: {}'.format(f1))\n",
        "print(classification_report(test_labels, test_predictions, target_names=mlb.classes_, zero_division=0))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "F1: 0.5303703703703704\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "        AMBIENCE#GENERAL       0.79      0.47      0.59        57\n",
            "           DRINKS#PRICES       0.00      0.00      0.00         3\n",
            "          DRINKS#QUALITY       0.00      0.00      0.00        21\n",
            "    DRINKS#STYLE_OPTIONS       0.00      0.00      0.00        12\n",
            "             FOOD#PRICES       0.00      0.00      0.00        22\n",
            "            FOOD#QUALITY       0.53      0.88      0.66       226\n",
            "      FOOD#STYLE_OPTIONS       0.00      0.00      0.00        48\n",
            "        LOCATION#GENERAL       0.00      0.00      0.00        13\n",
            "      RESTAURANT#GENERAL       0.61      0.56      0.58       142\n",
            "RESTAURANT#MISCELLANEOUS       0.00      0.00      0.00        33\n",
            "       RESTAURANT#PRICES       0.00      0.00      0.00        21\n",
            "         SERVICE#GENERAL       0.85      0.37      0.51       145\n",
            "\n",
            "               micro avg       0.59      0.48      0.53       743\n",
            "               macro avg       0.23      0.19      0.20       743\n",
            "            weighted avg       0.50      0.48      0.46       743\n",
            "             samples avg       0.53      0.45      0.48       743\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBLqZ6BMXeN7"
      },
      "source": [
        "## OutputCode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-zgMkaZXgLX",
        "outputId": "470c6f95-608b-4326-90d7-e4ed841411ae"
      },
      "source": [
        "from sklearn.multiclass import OutputCodeClassifier\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "text_clf_occ = Pipeline([\n",
        "     ('vect', CountVectorizer()),\n",
        "     ('tfidf', TfidfTransformer()), \n",
        "     ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)),\n",
        "     ('clf',  OutputCodeClassifier(LogisticRegression()))\n",
        " ])\n",
        "#train_labels_1vs1 = list(map(lambda x: get_index(x), train_labels))\n",
        "#text_clf_occ.fit(train_text, train_labels)\n",
        "\n",
        "#test_predictions = text_clf_occ.predict(test_text)\n",
        "\n",
        "#test_predictions = reverse(test_predictions)\n",
        "print(test_predictions)\n",
        "#test_labels_1vs1 = list(map(lambda x: get_index(x), test_labels))\n",
        "#print(test_predictions)\n",
        "f1 = f1_score(test_labels,\n",
        "         test_predictions,\n",
        "         average='micro')\n",
        "print('F1: {}'.format(f1))\n",
        "print(classification_report(test_labels, test_predictions, target_names=mlb.classes_, zero_division=0))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "F1: 0.5303703703703704\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "        AMBIENCE#GENERAL       0.79      0.47      0.59        57\n",
            "           DRINKS#PRICES       0.00      0.00      0.00         3\n",
            "          DRINKS#QUALITY       0.00      0.00      0.00        21\n",
            "    DRINKS#STYLE_OPTIONS       0.00      0.00      0.00        12\n",
            "             FOOD#PRICES       0.00      0.00      0.00        22\n",
            "            FOOD#QUALITY       0.53      0.88      0.66       226\n",
            "      FOOD#STYLE_OPTIONS       0.00      0.00      0.00        48\n",
            "        LOCATION#GENERAL       0.00      0.00      0.00        13\n",
            "      RESTAURANT#GENERAL       0.61      0.56      0.58       142\n",
            "RESTAURANT#MISCELLANEOUS       0.00      0.00      0.00        33\n",
            "       RESTAURANT#PRICES       0.00      0.00      0.00        21\n",
            "         SERVICE#GENERAL       0.85      0.37      0.51       145\n",
            "\n",
            "               micro avg       0.59      0.48      0.53       743\n",
            "               macro avg       0.23      0.19      0.20       743\n",
            "            weighted avg       0.50      0.48      0.46       743\n",
            "             samples avg       0.53      0.45      0.48       743\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMkKv3DbfLEw"
      },
      "source": [
        "# BERT approach\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p0VaHZP9Beu"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA2RSDiEfK28",
        "outputId": "d94ca024-0ded-4058-8c9f-f3558ebcf5bc"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "306lRrowfUcX",
        "outputId": "924db4f3-fcac-4ee9-b9cc-f59ec3582502"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch \n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCWWRqDhq_sb"
      },
      "source": [
        "## BERT tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRyFIFEArFiZ",
        "outputId": "c77cc21e-7935-4bd1-f85d-047d9b1b986e"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSzeXGhHrBz5"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd9yJce1s-Pb"
      },
      "source": [
        "## TextDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDj8xCpWtAIb"
      },
      "source": [
        "class TextLabelDataset (Dataset):\n",
        "    def __init__(self, text, labels, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text = text\n",
        "        self.labels = labels\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "    \n",
        "    def __getitem__(self, item_idx):\n",
        "        text = self.text[item_idx]\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length= self.max_len,\n",
        "            padding = 'max_length',\n",
        "            return_token_type_ids= False,\n",
        "            return_attention_mask= True,\n",
        "            truncation=True,\n",
        "            return_tensors = 'pt'\n",
        "          )\n",
        "        \n",
        "        input_ids = inputs['input_ids'].flatten()\n",
        "        attn_mask = inputs['attention_mask'].flatten()\n",
        "               \n",
        "        return {\n",
        "          'input_ids': input_ids ,\n",
        "          'attention_mask': attn_mask,\n",
        "          'label_ids':torch.tensor(self.labels[item_idx],dtype= torch.float)\n",
        "        }"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gWAr-Ndzvvd",
        "outputId": "1b0d3775-fddf-41da-e668-325f6ada004d"
      },
      "source": [
        "all_text = train_text + test_text\n",
        "all_text_lengths = map(lambda x: len(tokenizer.tokenize(x)), all_text)\n",
        "MAX_LEN = max(all_text_lengths) + 2\n",
        "print(MAX_LEN)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FmAeTiPx2jj"
      },
      "source": [
        "train_dataset = TextLabelDataset(train_text, train_labels, tokenizer, MAX_LEN)\n",
        "test_dataset = TextLabelDataset(test_text, test_labels, tokenizer, MAX_LEN)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwH569MgmCg_"
      },
      "source": [
        "## BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SSkpo3il2Fo"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel\n",
        "\n",
        "class MyBertModel(nn.Module):\n",
        "    def __init__(self, num_classes, device='cpu', finetuning=False):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased', \n",
        "                                              return_dict=True)\n",
        "\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "        self.device = device\n",
        "        self.finetuning = finetuning\n",
        "\n",
        "    def forward(self, x, attn):\n",
        "        '''\n",
        "        x: (N, T). int64\n",
        "        Returns\n",
        "        enc: (N, T, num_classes)\n",
        "        '''\n",
        "        x = x.to(self.device)\n",
        "        # feed input tokens through BERT\n",
        "        if self.training and self.finetuning:\n",
        "            self.bert.train()\n",
        "\n",
        "            outputs = self.bert(input_ids=x,attention_mask=attn)\n",
        "        else:\n",
        "            self.bert.eval()\n",
        "            with torch.no_grad():\n",
        "              outputs = self.bert(x)\n",
        "        logits = self.fc(outputs.pooler_output)\n",
        "\n",
        "        return self.sig(logits)\n",
        "    \n",
        "    def to_labels(self, result, threshold=0.5):\n",
        "        to_return = torch.empty_like(result)\n",
        "        for i in range(result.shape[0]):\n",
        "            for j in range(result.shape[1]):\n",
        "                if result[i][j] > threshold:\n",
        "                    to_return[i][j] = 1\n",
        "                else:\n",
        "                    to_return[i][j] = 0\n",
        "        return to_return\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGBEt5PjmFfd"
      },
      "source": [
        "## Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vAVZb2F7_Yj",
        "outputId": "2961fa27-bc29-47b5-e813-9cdc0c467f00"
      },
      "source": [
        "!pip install sklearn_crfsuite\n",
        "import sklearn_crfsuite\n",
        "import sklearn_crfsuite.metrics"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.9.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXK4N3hamHav"
      },
      "source": [
        "def train(model, num_epochs, train_iter, dev_iter):\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "  for epoch in range(1, num_epochs+1):\n",
        "    print(\"Epoch %d\" % epoch)\n",
        "    \n",
        "    for i, batch in enumerate(train_iter):\n",
        "        model.train()\n",
        "        x = batch[\"input_ids\"]\n",
        "        y = batch[\"label_ids\"]\n",
        "        attn = batch[\"attention_mask\"]\n",
        "\n",
        "        #print(x.shape)\n",
        "        #print(y.shape)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        x = x.to(device)\n",
        "        attn = attn.to(device)\n",
        "        logits = model(x, attn) # logits: (N, T, TAGS), y: (N, T)\n",
        "        #print(logits[0])\n",
        "\n",
        "        logits = logits.view(-1, logits.shape[-1]) # (N*T, TAGS)\n",
        "        y = y.to(device)\n",
        "        #y = y.view(-1)  # (N*T,)\n",
        "        #logits = logits.view(-1)\n",
        "        #print(logits.shape)\n",
        "        #print(y.shape)\n",
        "\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if i % 10 == 0: # monitoring\n",
        "            print(f\"step: {i}, loss: {loss.item()}\")\n",
        "\n",
        "        if i % 100 == 0: # let's evaluate more frequently than every epoch\n",
        "            evaluate(\"test set\", dev_iter, model)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmkTDgVcGfdQ"
      },
      "source": [
        "## Evaluate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSBatQWrGiet"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate(dataset_name, data_iter, model, full_report=False, threshold=0.5):\n",
        "  \n",
        "  model.eval()\n",
        "  not_started = True\n",
        "  with torch.no_grad():\n",
        "    for batch in data_iter:\n",
        "      x = batch[\"input_ids\"]\n",
        "      y = batch[\"label_ids\"]\n",
        "      attn = batch[\"attention_mask\"]\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      logits = model(x, attn)\n",
        "      y_pred = logits\n",
        "\n",
        "      if not_started:\n",
        "        y_seq = y\n",
        "        y_pred_seq = logits\n",
        "        not_started = False\n",
        "      else:\n",
        "        #print(y_seq.shape)\n",
        "        #print(y_pred_seq.shape)\n",
        "        y_seq = torch.cat((y_seq,y), dim=0)\n",
        "        y_pred_seq = torch.cat((y_pred_seq, y_pred), dim=0)\n",
        "  \n",
        "  y_pred_seq = model.to_labels(y_pred_seq, threshold)\n",
        "  y_seq = y_seq.cpu()\n",
        "  y_pred_seq = y_pred_seq.cpu()\n",
        "  accuracy = sklearn_crfsuite.metrics.flat_accuracy_score(y_seq, y_pred_seq)\n",
        "\n",
        "  f1 = f1_score(y_seq, y_pred_seq, average='micro')\n",
        "  \n",
        "  print('  Evaluation on {} -  acc: {:.4f}%'.format(dataset_name, accuracy))\n",
        "  print('     F1: {}'.format(f1))\n",
        "  if full_report:\n",
        "    print(classification_report(y_seq, y_pred_seq, target_names=list(TAGS)))\n",
        "  return f1"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POWaEnWjnRf_"
      },
      "source": [
        "## Model call"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO7Dvj2fnTtz",
        "outputId": "02f2ef1d-5c60-4fef-8467-bfa3383af3fd"
      },
      "source": [
        "model = MyBertModel(n_labels, device, True).to(device)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VUny0KGpQUw"
      },
      "source": [
        "## Batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpUaWt0MpSf5"
      },
      "source": [
        "# we use a small batch size, as BERT needs a lot of memory\n",
        "batch_size = 16\n",
        "\n",
        "train_iter = DataLoader(dataset=train_dataset,\n",
        "                                 batch_size=batch_size,\n",
        "                                 shuffle=True,\n",
        "                                 num_workers=2)\n",
        "dev_iter = DataLoader(dataset=test_dataset,\n",
        "                                 batch_size=batch_size,\n",
        "                                 shuffle=False,\n",
        "                                 num_workers=2)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7Dx82CJpZi9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezDsKWt1pb51",
        "outputId": "d0b06a97-3233-4343-9444-f114df272219"
      },
      "source": [
        "train(model, 10, train_iter, dev_iter)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "step: 0, loss: 0.6196693181991577\n",
            "  Evaluation on test set -  acc: 0.7885%\n",
            "     F1: 0.03160270880361174\n",
            "step: 10, loss: 0.3055298626422882\n",
            "step: 20, loss: 0.27759110927581787\n",
            "step: 30, loss: 0.2989870309829712\n",
            "step: 40, loss: 0.2749831974506378\n",
            "step: 50, loss: 0.2702799439430237\n",
            "step: 60, loss: 0.3013436198234558\n",
            "step: 70, loss: 0.26427024602890015\n",
            "step: 80, loss: 0.1893048733472824\n",
            "step: 90, loss: 0.21074943244457245\n",
            "step: 100, loss: 0.14482562243938446\n",
            "  Evaluation on test set -  acc: 0.9183%\n",
            "     F1: 0.32962588473205257\n",
            "step: 110, loss: 0.21011969447135925\n",
            "step: 120, loss: 0.17385362088680267\n",
            "Epoch 2\n",
            "step: 0, loss: 0.16001653671264648\n",
            "  Evaluation on test set -  acc: 0.9211%\n",
            "     F1: 0.33884297520661155\n",
            "step: 10, loss: 0.14535082876682281\n",
            "step: 20, loss: 0.18140272796154022\n",
            "step: 30, loss: 0.25704866647720337\n",
            "step: 40, loss: 0.1917060911655426\n",
            "step: 50, loss: 0.18021810054779053\n",
            "step: 60, loss: 0.1098458468914032\n",
            "step: 70, loss: 0.13499966263771057\n",
            "step: 80, loss: 0.18165743350982666\n",
            "step: 90, loss: 0.16537857055664062\n",
            "step: 100, loss: 0.15232513844966888\n",
            "  Evaluation on test set -  acc: 0.9331%\n",
            "     F1: 0.5355004277159966\n",
            "step: 110, loss: 0.12403813004493713\n",
            "step: 120, loss: 0.18176643550395966\n",
            "Epoch 3\n",
            "step: 0, loss: 0.14434298872947693\n",
            "  Evaluation on test set -  acc: 0.8926%\n",
            "     F1: 0.4220305242203053\n",
            "step: 10, loss: 0.10674216598272324\n",
            "step: 20, loss: 0.1081433892250061\n",
            "step: 30, loss: 0.13405463099479675\n",
            "step: 40, loss: 0.07080020755529404\n",
            "step: 50, loss: 0.1366071105003357\n",
            "step: 60, loss: 0.142001673579216\n",
            "step: 70, loss: 0.1096063181757927\n",
            "step: 80, loss: 0.14767199754714966\n",
            "step: 90, loss: 0.1666003316640854\n",
            "step: 100, loss: 0.1637418568134308\n",
            "  Evaluation on test set -  acc: 0.9072%\n",
            "     F1: 0.4571016582552271\n",
            "step: 110, loss: 0.05598265677690506\n",
            "step: 120, loss: 0.14046980440616608\n",
            "Epoch 4\n",
            "step: 0, loss: 0.13374587893486023\n",
            "  Evaluation on test set -  acc: 0.9376%\n",
            "     F1: 0.546594982078853\n",
            "step: 10, loss: 0.09835599362850189\n",
            "step: 20, loss: 0.09011392295360565\n",
            "step: 30, loss: 0.05522661656141281\n",
            "step: 40, loss: 0.07524898648262024\n",
            "step: 50, loss: 0.07621452957391739\n",
            "step: 60, loss: 0.12997859716415405\n",
            "step: 70, loss: 0.07640202343463898\n",
            "step: 80, loss: 0.08441438525915146\n",
            "step: 90, loss: 0.14114373922348022\n",
            "step: 100, loss: 0.0759778544306755\n",
            "  Evaluation on test set -  acc: 0.9448%\n",
            "     F1: 0.6131260794473229\n",
            "step: 110, loss: 0.08102038502693176\n",
            "step: 120, loss: 0.12336193770170212\n",
            "Epoch 5\n",
            "step: 0, loss: 0.0737961083650589\n",
            "  Evaluation on test set -  acc: 0.9444%\n",
            "     F1: 0.6257261410788382\n",
            "step: 10, loss: 0.07791557908058167\n",
            "step: 20, loss: 0.058057717978954315\n",
            "step: 30, loss: 0.07953473180532455\n",
            "step: 40, loss: 0.09281276166439056\n",
            "step: 50, loss: 0.09252715110778809\n",
            "step: 60, loss: 0.07650976628065109\n",
            "step: 70, loss: 0.07077188044786453\n",
            "step: 80, loss: 0.03748667985200882\n",
            "step: 90, loss: 0.09194718301296234\n",
            "step: 100, loss: 0.07248678803443909\n",
            "  Evaluation on test set -  acc: 0.9242%\n",
            "     F1: 0.5755693581780539\n",
            "step: 110, loss: 0.04525091499090195\n",
            "step: 120, loss: 0.045841120183467865\n",
            "Epoch 6\n",
            "step: 0, loss: 0.12396492809057236\n",
            "  Evaluation on test set -  acc: 0.9022%\n",
            "     F1: 0.4965079365079365\n",
            "step: 10, loss: 0.07245998084545135\n",
            "step: 20, loss: 0.08240941166877747\n",
            "step: 30, loss: 0.058732472360134125\n",
            "step: 40, loss: 0.06040602922439575\n",
            "step: 50, loss: 0.04600191116333008\n",
            "step: 60, loss: 0.0479932576417923\n",
            "step: 70, loss: 0.05639918893575668\n",
            "step: 80, loss: 0.04145115613937378\n",
            "step: 90, loss: 0.05323174595832825\n",
            "step: 100, loss: 0.10146450996398926\n",
            "  Evaluation on test set -  acc: 0.9406%\n",
            "     F1: 0.6298003072196621\n",
            "step: 110, loss: 0.04408229887485504\n",
            "step: 120, loss: 0.058247484266757965\n",
            "Epoch 7\n",
            "step: 0, loss: 0.05112333223223686\n",
            "  Evaluation on test set -  acc: 0.9172%\n",
            "     F1: 0.5980861244019138\n",
            "step: 10, loss: 0.03548014909029007\n",
            "step: 20, loss: 0.06367311626672745\n",
            "step: 30, loss: 0.028181880712509155\n",
            "step: 40, loss: 0.07210474461317062\n",
            "step: 50, loss: 0.04270346090197563\n",
            "step: 60, loss: 0.02835683897137642\n",
            "step: 70, loss: 0.06763078272342682\n",
            "step: 80, loss: 0.043113406747579575\n",
            "step: 90, loss: 0.04834296926856041\n",
            "step: 100, loss: 0.01954282820224762\n",
            "  Evaluation on test set -  acc: 0.9050%\n",
            "     F1: 0.4904163912756114\n",
            "step: 110, loss: 0.025451181456446648\n",
            "step: 120, loss: 0.07632456719875336\n",
            "Epoch 8\n",
            "step: 0, loss: 0.045110370963811874\n",
            "  Evaluation on test set -  acc: 0.9209%\n",
            "     F1: 0.599250936329588\n",
            "step: 10, loss: 0.0727873221039772\n",
            "step: 20, loss: 0.04042982682585716\n",
            "step: 30, loss: 0.05062790960073471\n",
            "step: 40, loss: 0.048353102058172226\n",
            "step: 50, loss: 0.017315441742539406\n",
            "step: 60, loss: 0.028279375284910202\n",
            "step: 70, loss: 0.015573732554912567\n",
            "step: 80, loss: 0.009921453893184662\n",
            "step: 90, loss: 0.021184157580137253\n",
            "step: 100, loss: 0.010288852266967297\n",
            "  Evaluation on test set -  acc: 0.8978%\n",
            "     F1: 0.5386755703951029\n",
            "step: 110, loss: 0.01760736107826233\n",
            "step: 120, loss: 0.03656958416104317\n",
            "Epoch 9\n",
            "step: 0, loss: 0.0397602878510952\n",
            "  Evaluation on test set -  acc: 0.8820%\n",
            "     F1: 0.4784741144414169\n",
            "step: 10, loss: 0.046275265514850616\n",
            "step: 20, loss: 0.05492163822054863\n",
            "step: 30, loss: 0.01952555775642395\n",
            "step: 40, loss: 0.05435967445373535\n",
            "step: 50, loss: 0.01286328211426735\n",
            "step: 60, loss: 0.05482122302055359\n",
            "step: 70, loss: 0.0495111458003521\n",
            "step: 80, loss: 0.037103746086359024\n",
            "step: 90, loss: 0.007746635936200619\n",
            "step: 100, loss: 0.015715643763542175\n",
            "  Evaluation on test set -  acc: 0.8979%\n",
            "     F1: 0.5509761388286334\n",
            "step: 110, loss: 0.02866138517856598\n",
            "step: 120, loss: 0.010749943554401398\n",
            "Epoch 10\n",
            "step: 0, loss: 0.016942042857408524\n",
            "  Evaluation on test set -  acc: 0.8812%\n",
            "     F1: 0.5426944971537002\n",
            "step: 10, loss: 0.010715842247009277\n",
            "step: 20, loss: 0.018306218087673187\n",
            "step: 30, loss: 0.08366738259792328\n",
            "step: 40, loss: 0.013597678393125534\n",
            "step: 50, loss: 0.005955275148153305\n",
            "step: 60, loss: 0.005646505858749151\n",
            "step: 70, loss: 0.019867438822984695\n",
            "step: 80, loss: 0.015019699931144714\n",
            "step: 90, loss: 0.022977640852332115\n",
            "step: 100, loss: 0.017157021909952164\n",
            "  Evaluation on test set -  acc: 0.8523%\n",
            "     F1: 0.4822817631806396\n",
            "step: 110, loss: 0.006308777257800102\n",
            "step: 120, loss: 0.014496701769530773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdkY_C2txEoD"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXZGF1ZmxERw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9362cbc3-cb9f-494f-f257-1e0aa8b59621"
      },
      "source": [
        "evaluate(\"dev\", dev_iter, model, full_report=True)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Evaluation on dev -  acc: 0.9377%\n",
            "     F1: 0.6718648473034438\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "        AMBIENCE#GENERAL       0.86      0.65      0.74        57\n",
            "           DRINKS#PRICES       0.50      0.33      0.40         3\n",
            "          DRINKS#QUALITY       0.50      0.24      0.32        21\n",
            "    DRINKS#STYLE_OPTIONS       0.32      0.75      0.45        12\n",
            "             FOOD#PRICES       0.75      0.14      0.23        22\n",
            "            FOOD#QUALITY       0.73      0.89      0.80       226\n",
            "      FOOD#STYLE_OPTIONS       0.71      0.25      0.37        48\n",
            "        LOCATION#GENERAL       1.00      0.38      0.56        13\n",
            "      RESTAURANT#GENERAL       0.50      0.85      0.63       142\n",
            "RESTAURANT#MISCELLANEOUS       0.00      0.00      0.00        33\n",
            "       RESTAURANT#PRICES       1.00      0.10      0.17        21\n",
            "         SERVICE#GENERAL       0.73      0.83      0.77       145\n",
            "\n",
            "               micro avg       0.65      0.70      0.67       743\n",
            "               macro avg       0.63      0.45      0.45       743\n",
            "            weighted avg       0.66      0.70      0.64       743\n",
            "             samples avg       0.60      0.62      0.60       743\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6718648473034438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpnRhPPVFDN1"
      },
      "source": [
        "# Iterative search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBpIYV8MFGT8"
      },
      "source": [
        "## Model call"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cutBDGwFIkE",
        "outputId": "dd5e56ef-4682-4988-960e-6b8b0999bec0"
      },
      "source": [
        "model2 = MyBertModel(n_labels, device, True).to(device)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUHLNSrSFnzt"
      },
      "source": [
        "## Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHdwEdLMFnLD"
      },
      "source": [
        "def train(model, num_epochs, train_iter, dev_iter, threshold,\n",
        "          learning_rate=0.0001):\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  f1_epochs = []\n",
        "  for epoch in range(1, num_epochs+1):\n",
        "    print(\"Epoch %d\" % epoch)\n",
        "    \n",
        "    for i, batch in enumerate(train_iter):\n",
        "        model.train()\n",
        "        x = batch[\"input_ids\"]\n",
        "        y = batch[\"label_ids\"]\n",
        "        attn = batch[\"attention_mask\"]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        x = x.to(device)\n",
        "        attn = attn.to(device)\n",
        "        logits = model(x, attn) \n",
        "\n",
        "        logits = logits.view(-1, logits.shape[-1]) # (N*T, TAGS)\n",
        "        y = y.to(device)\n",
        "\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "    f1_epochs.append(evaluate(\"test set\", dev_iter, model))\n",
        "\n",
        "  return evaluate(\"test set\", dev_iter, model), f1_epochs"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7DvuE4DGwt1"
      },
      "source": [
        "## Iterative learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rzHVHgFyGwYd",
        "outputId": "fd578ccb-0c0c-45cd-c89b-cba54fb61458"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "lrs = [0.00006, 0.00007, 0.00008, 0.00009,  0.0001, 0.00011, 0.00015] # already from 0.005 F1 gets 0 all the time\n",
        "thrs = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
        "results = np.zeros((len(lrs), len(thrs)))\n",
        "results_epochs = np.zeros((len(lrs), len(thrs)))\n",
        "i, j = 0, 0\n",
        "for lr in lrs:\n",
        "    j = 0\n",
        "    for th in thrs:\n",
        "        model2 = MyBertModel(n_labels, device, True).to(device)\n",
        "        print(('***********\\n' + \\\n",
        "              'Current iteration:\\n' + \\\n",
        "              '\\tLearning rate:\\t{}\\n'+ \\\n",
        "              '\\tThreshold:\\t{}\\n'+ \\\n",
        "              '***********').format(lr, th))\n",
        "        results[i][j], [i][j] = train(model2, 10, \n",
        "                                                    train_iter, dev_iter, \n",
        "                                                    th, learning_rate=lr)\n",
        "        j += 1\n",
        "    i += 1\n",
        "\n",
        "print(results)\n",
        "print(results_epochs)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***********\n",
            "Current iteration:\n",
            "\tLearning rate:\t6e-05\n",
            "\tThreshold:\t0.3\n",
            "***********\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "  Evaluation on test set -  acc: 0.9200%\n",
            "     F1: 0.5360972122944961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***********\n",
            "Current iteration:\n",
            "\tLearning rate:\t6e-05\n",
            "\tThreshold:\t0.35\n",
            "***********\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "  Evaluation on test set -  acc: 0.9410%\n",
            "     F1: 0.5923404255319149\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***********\n",
            "Current iteration:\n",
            "\tLearning rate:\t6e-05\n",
            "\tThreshold:\t0.4\n",
            "***********\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "  Evaluation on test set -  acc: 0.9184%\n",
            "     F1: 0.5496598639455783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***********\n",
            "Current iteration:\n",
            "\tLearning rate:\t6e-05\n",
            "\tThreshold:\t0.45\n",
            "***********\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "  Evaluation on test set -  acc: 0.9446%\n",
            "     F1: 0.6172208013640239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***********\n",
            "Current iteration:\n",
            "\tLearning rate:\t6e-05\n",
            "\tThreshold:\t0.5\n",
            "***********\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "  Evaluation on test set -  acc: 0.9390%\n",
            "     F1: 0.5495905368516834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***********\n",
            "Current iteration:\n",
            "\tLearning rate:\t6e-05\n",
            "\tThreshold:\t0.55\n",
            "***********\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "  Evaluation on test set -  acc: 0.9536%\n",
            "     F1: 0.7251461988304093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***********\n",
            "Current iteration:\n",
            "\tLearning rate:\t6e-05\n",
            "\tThreshold:\t0.6\n",
            "***********\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "  Evaluation on test set -  acc: 0.9417%\n",
            "     F1: 0.6381025248661055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***********\n",
            "Current iteration:\n",
            "\tLearning rate:\t6e-05\n",
            "\tThreshold:\t0.65\n",
            "***********\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "  Evaluation on test set -  acc: 0.9495%\n",
            "     F1: 0.7347994825355757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***********\n",
            "Current iteration:\n",
            "\tLearning rate:\t6e-05\n",
            "\tThreshold:\t0.7\n",
            "***********\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "  Evaluation on test set -  acc: 0.9498%\n",
            "     F1: 0.7191166321601105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***********\n",
            "Current iteration:\n",
            "\tLearning rate:\t7e-05\n",
            "\tThreshold:\t0.3\n",
            "***********\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "  Evaluation on test set -  acc: 0.8995%\n",
            "     F1: 0.5318782309017805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-c5e22f8c562f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyBertModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'***********\\n'\u001b[0m \u001b[0;34m+\u001b[0m               \u001b[0;34m'Current iteration:\\n'\u001b[0m \u001b[0;34m+\u001b[0m               \u001b[0;34m'\\tLearning rate:\\t{}\\n'\u001b[0m\u001b[0;34m+\u001b[0m               \u001b[0;34m'\\tThreshold:\\t{}\\n'\u001b[0m\u001b[0;34m+\u001b[0m               \u001b[0;34m'***********'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 9 is out of bounds for axis 0 with size 9"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpT66S_g_Fxb"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CotTOmH__HqP"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "for i in range(len(results)):\n",
        "    plt.plot(thrs,results[i][:], label=str(lrs[i]))\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('F1 score')\n",
        "plt.xlabel('Threshold value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05j4m9Hr0u7l"
      },
      "source": [
        "## Training with found parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJQ_ChD505F3"
      },
      "source": [
        "model3 = MyBertModel(n_labels, device, True).to(device)\n",
        "train(model3, 15, train_iter, dev_iter, 0.6, learning_rate=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I3nTxsiGvB9"
      },
      "source": [
        "evaluate(\"dev\", dev_iter, model3, full_report=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjvf6t71uhy1"
      },
      "source": [
        "# Predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcnUEYmKuj3Y"
      },
      "source": [
        "def return_true(x, y):\n",
        "  if x:\n",
        "    return y\n",
        "  else:\n",
        "    return ''\n",
        "\n",
        "  \n",
        "def predictor(model, text, threshold=0.6):\n",
        "    model.eval()\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        text,\n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        max_length= MAX_LEN,\n",
        "        padding = 'max_length',\n",
        "        return_token_type_ids= False,\n",
        "        return_attention_mask= True,\n",
        "        truncation=True,\n",
        "        return_tensors = 'pt'\n",
        "      )\n",
        "    \n",
        "    input_ids = inputs['input_ids'].flatten()\n",
        "    attn_mask = inputs['attention_mask'].flatten()\n",
        "\n",
        "    output = model(input_ids, attn_mask)\n",
        "    labels = model.to_labels(output, threshold)\n",
        "    return list(map(lambda x, y: y if x else '', labels, TAGS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7DGfHcxvYC1"
      },
      "source": [
        "Some examples:\n",
        "\n",
        "*   \"I was very disappointed with this restaurant.\" -> RESTAURANT#GENERAL\n",
        "*   \"I’ve asked a cart attendant for a lotus leaf wrapped rice and she replied back rice and just walked away.\" -> SERVICE#GENERAL\n",
        "*   \"Chow fun was dry; pork shu mai was more than usually greasy and had to share a table with loud and rude family.\" -> FOOD#QUALITY, AMBIENCE#GENERAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82lrEIZ02JBU"
      },
      "source": [
        "test1 = \"I was very disappointed with this restaurant.\"\n",
        "test2 = \"I’ve asked a cart attendant for a lotus leaf wrapped rice and she replied back rice and just walked away.\"\n",
        "test3 = \"Chow fun was dry; pork shu mai was more than usually greasy and had to share a table with loud and rude family.\"\n",
        "\n",
        "print(predictor(model3, test1)) # RESTAURANT#GENERAL\n",
        "print(predictor(model3, test2)) # SERVICE#GENERAL\n",
        "print(predictor(model3, test3)) # FOOD#QUALITY, AMBIENCE#GENERAL"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}